{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.facebook.com%2Fbellabeat%2F&psig=AOvVaw2hwhGnwByq57xsqUnyt_xN&ust=1666099732137000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCLDztamv5_oCFQAAAAAdAAAAABAE](http://)","metadata":{}},{"cell_type":"markdown","source":"Summary: As a small yet successful company in the fitness smart device market, Bellabeat is looking to analyze smart device data to unlock new growth opportunities for the company. \n\n **Case Study Road Map:**\n \n**ASK -**\n\n**What is the business task?**  The goal of this task is to study non-Bellabeat device data to find trends and then determine marketing strategies Bellabeat could benefit from.\n\n**Stakeholders**  Our main stakeholders are Bellabeat's cofounders, Urška Sršen and Sando Mur, and Bellabeat's executive team. We will also be communicating our findings to Bellabeat's marketing analytics team.\n\n**PREPARE -**\n\n**Data Source**  The data provided by Bellabeat's cofounder is the FitBit Fitness Tracker Dataset, which is a public domain. The dataset is also avaiable on Kaggle: https://kaggle.com/arashnic/fitbit\n\n**Data Integrity**  The dataset can be assessed using ROCCC: \n    \n    *Reliability:*\n        \nThe dataset includes data from around 30 individuals. While this is a small amount, it is large enough to be reliable. There has not, however, been any demographic information provided, so we do not know how varied the users are. At this point, more reliable data may be sought out, but we will use it for the case study anyway.\n\n    *Original:*  \n       \nThe data was collected from thirty FitBit users via a survey distributed by Amazon Mechanical Turk between 03/12/2016-05/12/2016.\n\n    *Comprehensive:*  \n    \nThis dataset contains 18 csv files, which include minute-level output for physical activity, heart rate, weight, and sleep monitoring data for 30 individuals over a span of two months. A more in depth outline of our data:\n\n* Daily activity\n* Calories burned (daily, hourly, by minute)\n* Intensities (daily, hourly, by minute)\n* Steps (daily, hourly)\n* Heart rate\n* METs\n* Sleep (by day and duration recorded as minutes)\n* Weight log information\n\n    *Current:*\n\nThis data was collected in 2016, so it is therefore NOT current. We will still use it for this case study to practice data analytics.\n\n    *Cited:*\n    \nFurberg, Robert; Brinton, Julia' Keating, Michael; Ortiz, Alexa https://zenodo.org/record/53894#.Yg6vfBPMK3J\n\n\n**PROCESS -**\n\nFor this data analysis, I will be using R due to the size of the datasets, as well as the ability to create data visualizations. This will allow me to summarize and share my insights with key stakeholders.\n\nPackages:\n\nFor the first step in the data cleaning process, we need to install/load the necessary packages:\n\n\n","metadata":{}},{"cell_type":"code","source":"install.packages(\"tidyverse\")\ninstall.packages(\"readr\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"tidyr\")\n\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(vctrs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data:**\n\nNext, we need to import and rename the Fitbit data that was provided for the case study:","metadata":{}},{"cell_type":"code","source":"daily_activity <- read_csv(\"dailyActivity_merged.csv\")\ndaily_calories <- read_csv(\"dailyCalories_merged.csv\")\ndaily_intensities <- read_csv(\"dailyIntensities_merged.csv\")\ndaily_steps <- read_csv(\"dailySteps_merged.csv\")\nheartrate_seconds <- read_csv(\"heartrate_seconds_merged.csv\")\nhourly_calories <- read_csv(\"hourlyCalories_merged.csv\")\nhourly_intensities <- read_csv(\"hourlyIntensities_merged.csv\")\nhourly_steps <- read_csv(\"hourlySteps_merged.csv\")\nminute_calories_N <- read_csv(\"minuteCaloriesNarrow_merged.csv\")\nminute_calories_W <- read_csv(\"minuteCaloriesWide_merged.csv\")\nminute_intensities_N <- read_csv(\"minuteIntensitiesNarrow_merged.csv\")\nminute_intensities_W <- read_csv(\"minuteIntensitiesWide_merged.csv\")\nminute_mets <- read_csv(\"minuteMETsNarrow_merged.csv\")\nminute_sleep <- read_csv(\"minuteSleep_merged.csv\")\nminute_steps_N <- read_csv(\"minuteStepsNarrow_merged.csv\")\nminute_steps_W <- read_csv(\"minuteStepsWide_merged.csv\")\nweight_log <- read_csv(\"weightLogInfo_merged.csv\")\nsleep_day <- read_csv(\"sleepDay_merged.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Cleaning:**\n\nIn order to get a better idea of the data we are working with, we will first preview the provided datasets:","metadata":{}},{"cell_type":"code","source":"glimpse(daily_activity)\nglimpse(daily_calories)\nglimpse(daily_intensities)\nglimpse(daily_steps)\nglimpse(heartrate_seconds)\nglimpse(hourly_calories)\nglimpse(hourly_intensities)\nglimpse(hourly_steps)\nglimpse(minute_calories_N)\nglimpse(minute_calories_W)\nglimpse(minute_intensities_N)\nglimpse(minute_intensities_W)\nglimpse(minute_mets)\nglimpse(minute_sleep)\nglimpse(minute_steps_N)\nglimpse(minute_steps_W)\nglimpse(weight_log)\nglimpse(sleep_day)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Due to there being so many datasets, let's try to narrow our search. We wil now be checking the datasets for distinct users  or looking for incomplete datasets:","metadata":{}},{"cell_type":"code","source":"n_distinct(heartrate_seconds$Id)\nn_distinct(minute_sleep$Id)\nn_distinct(weight_log$Id)\nn_distinct(sleep_day$Id)\nn_distinct(minute_steps_W$Id)\nn_distinct(minute_steps_N$Id)\nn_distinct(minute_mets$Id)\nn_distinct(minute_intensities_W$Id)\nn_distinct(minute_intensities_N$Id)\nn_distinct(minute_calories_N$Id)\nn_distinct(minute_calories_W$Id)\nn_distinct(hourly_steps$Id)\nn_distinct(hourly_intensities$Id)\nn_distinct(hourly_calories$Id)\nn_distinct(daily_steps$Id)\nn_distinct(daily_intensities$Id)\nn_distinct(daily_calories$Id)\nn_distinct(daily_activity$Id)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4 of the datasets above had significantly less user id's than the others. While many analysts might ignore these sets and focus on the remainder, I like the road less traveled. Of the 4, 1 does not seem to have much useful information, so we will examine the other 3 more closely to figure out why they are incomplete. Could this be helpful for Bellabeat?\n\nWe will be looking closer at:\n\n1. weight_log\n2. sleep_day\n3. heartrate_seconds\n\nTo begin, lets check the datasets for empty fields. This will allow us to remove blanks and clean up our data.\n","metadata":{}},{"cell_type":"code","source":"heartrate_seconds <- heartrate_seconds[complete.cases(heartrate_seconds), ]\nweight_log <- weight_log[complete.cases(weight_log), ]\nsleep_day <- sleep_day[complete.cases(sleep_day), ]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next step is to use those datasets to look for duplicates. They may not have blanks, but they may have repeated data:","metadata":{}},{"cell_type":"code","source":"sum(duplicated(sleep_day))\nsum(duplicated(weight_log))\nsum(duplicated(heartrate_seconds))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since only 1 dataset showed duplicates, let's remove them:","metadata":{}},{"cell_type":"code","source":"sleep_day <- sleep_day[!duplicated(sleep_day), ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analyze:**\n\nNow that our data is cleaner, we still need to address formatting. Let's check the dates in each of the datasets to see if they are in date format:","metadata":{}},{"cell_type":"code","source":"str(heartrate_seconds)\nstr(weight_log)\nstr(sleep_day)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like they are string format, so we will need to change that in case we need to compare dates at a later point:","metadata":{}},{"cell_type":"code","source":"data$date <- as.Date(data$date)\nheartrate_seconds$Time <- mdy_hms(heartrate_seconds$Time)\nsleep_day$SleepDay <-mdy_hms(sleep_day$SleepDay)\nweight_log$Date <-mdy_hms(weight_log$Date)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's confirm it worked and that the dates are in the correct format now:","metadata":{}},{"cell_type":"code","source":"str(heartrate_seconds)\nstr(weight_log)\nstr(sleep_day)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are going to group our data by Id to see if the user Id's are consistent. Are there users who took advantage of ALL Fitbit capabilities. Are these \"super users\" and therefore showing up in all of our datasets?","metadata":{}},{"cell_type":"code","source":"vec_count(heartrate_seconds$Id, sort = \"key\")\nvec_count(sleep_day$Id, sort = \"key\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The answer is no. The Id's are not consistent between the datasets. Data shows that its all over the board and usage is not consistent by user. While some users are not using their fitbit for weight or sleep, some are using it intermittently. Others are getting inconsistent heartrate data, likely from improper wear or from removal of device.\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}